{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d327b15-9580-4362-8e4d-ed2c3506f984",
   "metadata": {},
   "source": [
    "\n",
    "## 1: Transform the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "18ee094c-0d05-45d6-94c6-50a944e0160d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative               int64\n",
       "Administrative_Duration    float64\n",
       "Informational                int64\n",
       "Informational_Duration     float64\n",
       "ProductRelated               int64\n",
       "ProductRelated_Duration    float64\n",
       "BounceRates                float64\n",
       "ExitRates                  float64\n",
       "PageValues                 float64\n",
       "SpecialDay                 float64\n",
       "Month                       object\n",
       "OperatingSystems             int64\n",
       "Browser                      int64\n",
       "Region                       int64\n",
       "TrafficType                  int64\n",
       "VisitorType                 object\n",
       "Weekend                       bool\n",
       "Revenue                       bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import math\n",
    "\n",
    "#create a path to the file\n",
    "\n",
    "file_path = \"shopping.csv\"\n",
    "\n",
    "#read the csv file a pandas dataframe\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "#print the dataframe column data types\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f4ddec72-65d2-4bcf-b883-dabe1ffbe25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>142.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48</td>\n",
       "      <td>1052.255952</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0.013043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>437.391304</td>\n",
       "      <td>2</td>\n",
       "      <td>235.55</td>\n",
       "      <td>83</td>\n",
       "      <td>2503.881781</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>2.086218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mar</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>41.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>126</td>\n",
       "      <td>4310.004668</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>3.451072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>606.666667</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>36.672294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Aug</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>608.140000</td>\n",
       "      <td>6</td>\n",
       "      <td>733.80</td>\n",
       "      <td>168</td>\n",
       "      <td>4948.398759</td>\n",
       "      <td>0.006632</td>\n",
       "      <td>0.013528</td>\n",
       "      <td>10.150644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Aug</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>415.250000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.048148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mar</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>186.933333</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>May</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mar</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>149.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>55</td>\n",
       "      <td>2598.991667</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>48.729956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>May</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>140.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>88.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>May</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>New_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               3               142.500000              0   \n",
       "1               6               437.391304              2   \n",
       "2               1                41.125000              0   \n",
       "3               2               141.000000              0   \n",
       "4              18               608.140000              6   \n",
       "5               1                22.000000              0   \n",
       "6               0                 0.000000              0   \n",
       "7               0                 0.000000              0   \n",
       "8               8               149.500000              0   \n",
       "9               6               140.333333              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                    0.00              48              1052.255952   \n",
       "1                  235.55              83              2503.881781   \n",
       "2                    0.00             126              4310.004668   \n",
       "3                    0.00              10               606.666667   \n",
       "4                  733.80             168              4948.398759   \n",
       "5                    0.00               9               415.250000   \n",
       "6                    0.00              14               186.933333   \n",
       "7                    0.00              12               198.000000   \n",
       "8                    0.00              55              2598.991667   \n",
       "9                    0.00               9                88.950000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0     0.004348   0.013043    0.000000         0.0   Nov                 1   \n",
       "1     0.002198   0.004916    2.086218         0.0   Mar                 2   \n",
       "2     0.000688   0.012823    3.451072         0.0   Nov                 2   \n",
       "3     0.008333   0.026389   36.672294         0.0   Aug                 2   \n",
       "4     0.006632   0.013528   10.150644         0.0   Aug                 2   \n",
       "5     0.033333   0.048148    0.000000         0.0   Mar                 3   \n",
       "6     0.042857   0.071429    0.000000         0.0   May                 2   \n",
       "7     0.016667   0.075000    0.000000         0.0   Mar                 2   \n",
       "8     0.003279   0.008197   48.729956         0.0   May                 2   \n",
       "9     0.000000   0.004762    0.000000         0.0   May                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        8       6           11  Returning_Visitor    False    False  \n",
       "1        2       3            2  Returning_Visitor    False     True  \n",
       "2        2       2            2  Returning_Visitor    False    False  \n",
       "3        5       7            4  Returning_Visitor    False    False  \n",
       "4        2       3            1  Returning_Visitor     True    False  \n",
       "5        3       1            1  Returning_Visitor    False    False  \n",
       "6        2       3            4  Returning_Visitor    False    False  \n",
       "7        2       3            2  Returning_Visitor    False    False  \n",
       "8        4       8            2  Returning_Visitor     True    False  \n",
       "9        2       2            3        New_Visitor    False    False  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #show first 10 data lines\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "eedee2ed-7920-4876-a050-22c2fb970c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a mapping scheme for the values not a number\n",
    "bool_mapping={\n",
    "    \"TRUE\":1,\n",
    "    \"FALSE\":0\n",
    "}\n",
    "\n",
    "visitor_mapping={\n",
    "    \"Returning_Visitor\":1,\n",
    "    \"New_Visitor\":2,\n",
    "    \"Other\":3\n",
    "}\n",
    "\n",
    "month_mapping={\n",
    "    \"Jan\":1,\n",
    "    \"Feb\":2,\n",
    "    \"Mar\":3,\n",
    "    \"Apr\":4,\n",
    "    \"May\":5,\n",
    "    \"June\":6,\n",
    "    \"Jul\":7,\n",
    "    \"Aug\":8,\n",
    "    \"Sep\":9,\n",
    "    \"Oct\":10,\n",
    "    \"Nov\":11,\n",
    "    \"Dec\":12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "63811316-7b6e-4a8d-af71-558ad7678eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Revenue']=df['Revenue'].astype(str)\n",
    "df['Weekend']=df['Weekend'].astype(str)\n",
    "df['Revenue'] = df['Revenue'].str.upper()\n",
    "df['Weekend'] = df['Weekend'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ce971ed5-19d1-4b51-8613-1ce63134f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = df['Month'].replace(month_mapping)\n",
    "df['VisitorType'] = df['VisitorType'].replace(visitor_mapping)\n",
    "df['Revenue'] = df['Revenue'].replace(bool_mapping)  \n",
    "df['Weekend'] = df['Weekend'].replace(bool_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d2609a2a-e198-4240-a343-ec03cb4c3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df):\n",
    "    # Ensure the DataFrame is already transformed (with all floats and ints)\n",
    "    \n",
    "    # Split the data into features (X) and target (y)\n",
    "    X = df.iloc[:, :-1].values  # All columns except the last\n",
    "    y = df.iloc[:, -1].values    # The last column\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370392ef-976b-4365-a410-568de0446298",
   "metadata": {},
   "source": [
    "## 2: Split The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a5cdfed8-b1c6-401f-a8a0-492294142fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(5000, 17)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "#Load the data in and save the mappings we did\n",
    "X_train, y_train = load_data(df)\n",
    "print(type(X_train))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4aa484-ce6c-496d-8a6f-c6985706ed78",
   "metadata": {},
   "source": [
    "## 3: Implementation of Scalers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "074f4b30-8de7-468c-a506-3a90ecfb50e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMax Scaling\n",
    "def min_max_scaling(data):\n",
    "    scaled_data = data.copy()\n",
    "    \n",
    "    if len(data.shape) == 1:  # 1D array (like y_train)\n",
    "        min_value = data.min()\n",
    "        max_value = data.max()\n",
    "        scaled_data = (data - min_value) / (max_value - min_value)\n",
    "    \n",
    "    else:  # 2D array (like X_train)\n",
    "        for i in range(data.shape[1]):\n",
    "            min_value = data[:, i].min()\n",
    "            max_value = data[:, i].max()\n",
    "            scaled_data[:, i] = (data[:, i] - min_value) / (max_value - min_value)\n",
    "    \n",
    "    return scaled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c592c52a-1761-40d6-969d-9142c3c4a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Normalization Scaling\n",
    "def mean_normalization(data):\n",
    "    scaled_data = data.copy()\n",
    "    \n",
    "    if len(data.shape) == 1:  # Handle 1D array like y_train\n",
    "        mean_value = data.mean()\n",
    "        min_value = data.min()\n",
    "        max_value = data.max()\n",
    "        scaled_data = (data - mean_value) / (max_value - min_value)\n",
    "    \n",
    "    else:  # Handle 2D array like X_train\n",
    "        for i in range(data.shape[1]):  # Loop through columns using NumPy's indexing\n",
    "            mean_value = data[:, i].mean()\n",
    "            min_value = data[:, i].min()\n",
    "            max_value = data[:, i].max()\n",
    "            scaled_data[:, i] = (data[:, i] - mean_value) / (max_value - min_value)\n",
    "    \n",
    "    return scaled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a551cf4a-9b46-4440-91df-c1fcbd9d952d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Z-score normalization\n",
    "def z_score_normalization(data):\n",
    "    scaled_data = data.copy()\n",
    "    \n",
    "    if len(data.shape) == 1:  # Handle 1D array like y_train\n",
    "        mean_value = data.mean()\n",
    "        std_value = data.std()\n",
    "        scaled_data = (data - mean_value) / std_value\n",
    "    \n",
    "    else:  # Handle 2D array like X_train\n",
    "        for i in range(data.shape[1]):  # Loop through columns using NumPy's indexing\n",
    "            mean_value = data[:, i].mean()\n",
    "            std_value = data[:, i].std()\n",
    "            scaled_data[:, i] = (data[:, i] - mean_value) / std_value\n",
    "    \n",
    "    return scaled_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd86b8-9b7f-489a-a54f-d2d8bab2c68b",
   "metadata": {},
   "source": [
    "## 3.1: Initalize the Scalers to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "32543bb1-2348-47f1-918e-5d367c058891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the Min-Max scale\n",
    "X_train_minmax = min_max_scaling(X_train)\n",
    "y_train_minmax = min_max_scaling(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4e341ab0-c1ad-4f9f-9d68-3dcf30807f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the normalization scale\n",
    "X_train_normal = mean_normalization(X_train)\n",
    "y_train_normal = mean_normalization(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "29bc6541-d223-4f91-ac55-1e2aa0d2e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement z_score_normal\n",
    "X_train_Z = z_score_normalization(X_train)\n",
    "y_train_Z = z_score_normalization(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe001263-db56-42e6-b837-448b494bd826",
   "metadata": {},
   "source": [
    "## 4: Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f5baaac4-f7cb-40aa-ac40-4fad15e1482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7157a7de-c58e-44fc-9f33-024ac816c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Cost Function\n",
    "def compute_cost(X, y, w, b, *argv):\n",
    "    \"\"\"\n",
    "    Computes the cost over all examples\n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
    "      y : (ndarray Shape (m,)) target value \n",
    "      w : (ndarray Shape (n,)) values of parameters of the model      \n",
    "      b : (scalar) value of bias parameter of the model\n",
    "      *argv : unused, for compatibility with regularized version below\n",
    "    Returns:\n",
    "      total_cost : (scalar) cost \n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    z = np.dot(X, w) + b\n",
    "    h = sigmoid(z)\n",
    "    \n",
    "    # Compute cost\n",
    "    cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    \n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d2f4f87d-ab15-4d71-a780-898c10578080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at initial w and b (zeros) 0.693\n"
     ]
    }
   ],
   "source": [
    "m,n = X_train.shape\n",
    "\n",
    "initial_w = np.zeros(X_train.shape[1])  # Initialize weights for the number of features\n",
    "initial_b = 0.\n",
    "cost = compute_cost(X_train,y_train, initial_w, initial_b)\n",
    "print('cost at initial w and b (zeros) {:.3f}'.format(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3000501f-b8ae-4036-b13e-f56b64d0699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b, *argv):\n",
    "    \"\"\"\n",
    "    Computes the gradient for logistic regression \n",
    " \n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
    "      y : (ndarray Shape (m,))  target value \n",
    "      w : (ndarray Shape (n,))  values of parameters of the model      \n",
    "      b : (scalar)              value of bias parameter of the model\n",
    "      *argv : unused, for compatibility with regularized version below\n",
    "    Returns\n",
    "      dj_dw : (ndarray Shape (n,)) The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db : (scalar)             The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    z = np.dot(X, w) + b\n",
    "    h = sigmoid(z)\n",
    "    \n",
    "    dj_dw = (1/m) * np.dot(X.T, (h - y))\n",
    "    dj_db = (1/m) * np.sum(h - y)\n",
    "    \n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d9245ecc-06f5-4019-8c8f-6deeb2d120c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters, lambda_):\n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X :    (ndarray Shape (m, n) data, m examples by n features\n",
    "      y :    (ndarray Shape (m,))  target value \n",
    "      w_in : (ndarray Shape (n,))  Initial values of parameters of the model\n",
    "      b_in : (scalar)              Initial value of parameter of the model\n",
    "      cost_function :              function to compute cost\n",
    "      gradient_function :          function to compute gradient\n",
    "      alpha : (float)              Learning rate\n",
    "      num_iters : (int)            number of iterations to run gradient descent\n",
    "      lambda_ : (scalar, float)    regularization constant\n",
    "      \n",
    "    Returns:\n",
    "      w : (ndarray Shape (n,)) Updated values of parameters of the model after\n",
    "          running gradient descent\n",
    "      b : (scalar)                Updated value of parameter of the model after\n",
    "          running gradient descent\n",
    "    \"\"\"    \n",
    "    m = len(X)\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        dj_dw, dj_db = gradient_function(X, y, w_in, b_in, lambda_)\n",
    "        w_in = w_in - alpha * dj_dw\n",
    "        b_in = b_in - alpha * dj_db\n",
    "        \n",
    "        if i < 100000:\n",
    "            cost = cost_function(X, y, w_in, b_in, lambda_)\n",
    "            J_history.append(cost)\n",
    "        \n",
    "        if i % math.ceil(num_iters / 10) == 0 or i == (num_iters - 1):\n",
    "            w_history.append(w_in)\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}\")\n",
    "    \n",
    "    return w_in, b_in, J_history, w_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1854f2-e2c0-48d4-b533-3d5771cc2b74",
   "metadata": {},
   "source": [
    "## 5: Training The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "57107b80-246b-451f-9cfe-fa574e916056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/y6357rqx1q50rp0pj5z89z980000gn/T/ipykernel_16403/4178174508.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n",
      "/var/folders/5w/y6357rqx1q50rp0pj5z89z980000gn/T/ipykernel_16403/781981274.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
      "/var/folders/5w/y6357rqx1q50rp0pj5z89z980000gn/T/ipykernel_16403/781981274.py:19: RuntimeWarning: invalid value encountered in multiply\n",
      "  cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost      nan\n",
      "Iteration 1500: Cost      nan\n",
      "Iteration 3000: Cost      nan\n",
      "Iteration 4500: Cost      nan\n",
      "Iteration 6000: Cost      nan\n",
      "Iteration 7500: Cost      nan\n",
      "Iteration 9000: Cost      nan\n",
      "Iteration 10500: Cost      nan\n",
      "Iteration 12000: Cost      nan\n",
      "Iteration 13500: Cost      nan\n",
      "Iteration 14999: Cost      nan\n"
     ]
    }
   ],
   "source": [
    "#Training with NO Scaling\n",
    "initial_w = np.zeros(X_train.shape[1])  # or use small random values\n",
    "initial_b = 0.0\n",
    "\n",
    "iterations = 15000\n",
    "alpha = 0.0001\n",
    "\n",
    "w, b, J_history, _ = gradient_descent(X_train, y_train, initial_w, initial_b, compute_cost, compute_gradient, alpha, iterations, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "83c2dffb-8bac-4cf4-8961-760062390650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     0.69\n",
      "Iteration 3000: Cost     0.41\n",
      "Iteration 6000: Cost     0.40\n",
      "Iteration 9000: Cost     0.39\n",
      "Iteration 12000: Cost     0.38\n",
      "Iteration 15000: Cost     0.38\n",
      "Iteration 18000: Cost     0.38\n",
      "Iteration 21000: Cost     0.37\n",
      "Iteration 24000: Cost     0.37\n",
      "Iteration 27000: Cost     0.37\n",
      "Iteration 29999: Cost     0.36\n"
     ]
    }
   ],
   "source": [
    "#Training with MINMAX\n",
    "initial_w = np.zeros(X_train_minmax.shape[1])  # or use small random values\n",
    "w_random = np.random.randn(X_train_minmax.shape[1]) * 0.01\n",
    "\n",
    "initial_b = 0.0\n",
    "\n",
    "iterations = 30000\n",
    "alpha = 0.01\n",
    "\n",
    "w, b, J_history, _ = gradient_descent(X_train_minmax, y_train_minmax,initial_w, initial_b, compute_cost, compute_gradient, alpha, iterations, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "71ef8fe4-ff39-4363-8b6d-3ccdde438a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     0.69\n",
      "Iteration 3000: Cost     0.29\n",
      "Iteration 6000: Cost     0.17\n",
      "Iteration 9000: Cost     0.11\n",
      "Iteration 12000: Cost     0.08\n",
      "Iteration 15000: Cost     0.06\n",
      "Iteration 18000: Cost     0.04\n",
      "Iteration 21000: Cost     0.03\n",
      "Iteration 24000: Cost     0.02\n",
      "Iteration 27000: Cost     0.01\n",
      "Iteration 29999: Cost     0.01\n"
     ]
    }
   ],
   "source": [
    "#trainng with normalization\n",
    "#Training with MINMAX\n",
    "initial_w = np.zeros(X_train_normal.shape[1])  # or use small random values\n",
    "initial_b = 0.0\n",
    "\n",
    "iterations = 30000\n",
    "alpha = 0.001\n",
    "\n",
    "w, b, J_history, _ = gradient_descent(X_train_normal, y_train_normal,initial_w, initial_b, compute_cost, compute_gradient, alpha, iterations, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dbb82754-2181-43b7-8425-3b7ead954e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     0.69\n",
      "Iteration 3000: Cost     0.37\n",
      "Iteration 6000: Cost     0.14\n",
      "Iteration 9000: Cost    -0.04\n",
      "Iteration 12000: Cost    -0.20\n",
      "Iteration 15000: Cost    -0.33\n",
      "Iteration 18000: Cost    -0.45\n",
      "Iteration 21000: Cost    -0.57\n",
      "Iteration 24000: Cost    -0.67\n",
      "Iteration 27000: Cost    -0.78\n",
      "Iteration 29999: Cost    -0.87\n"
     ]
    }
   ],
   "source": [
    "#Training with z-score normal\n",
    "initial_w = np.zeros(X_train_Z.shape[1])\n",
    "initial_b = 0.0\n",
    "\n",
    "iterations = 30000\n",
    "alpha = 0.0002\n",
    "\n",
    "w, b, J_history, _ = gradient_descent(X_train_Z, y_train_Z,initial_w, initial_b, compute_cost, compute_gradient, alpha, iterations, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5f5cc1-41fe-4744-bb41-956d5da9d912",
   "metadata": {},
   "source": [
    "## 6: Get Predictions and Accuracys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0dabfca4-b130-4e33-be04-8d873658b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(X, w, b): \n",
    "    \"\"\"\n",
    "    Predict whether the label is 0 or 1 using learned logistic\n",
    "    regression parameters w\n",
    "    \n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
    "      w : (ndarray Shape (n,))  values of parameters of the model      \n",
    "      b : (scalar)              value of bias parameter of the model\n",
    "\n",
    "    Returns:\n",
    "      p : (ndarray (m,)) The predictions for X using a threshold at 0.5\n",
    "    \"\"\"\n",
    "    # number of training examples\n",
    "    m, n = X.shape   \n",
    "    p = np.zeros(m)\n",
    "   \n",
    "    ### START CODE HERE ### \n",
    "    # Loop over each example\n",
    "    for i in range(m):   \n",
    "        z_wb = np.dot(X[i],w) + b\n",
    "        \n",
    "        # Calculate the prediction for this example\n",
    "        f_wb = sigmoid(z_wb)\n",
    "\n",
    "        # Apply the threshold\n",
    "        if f_wb >= 0.5:\n",
    "            p[i] = 1\n",
    "        else:\n",
    "            p[i] = 0\n",
    "        \n",
    "        \n",
    "    ### END CODE HERE ### \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "323dcb05-8c70-434d-8b4d-94c51cb421b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 84.680000\n"
     ]
    }
   ],
   "source": [
    "#MINMAX ACCURACY\n",
    "p = predict(X_train_minmax, w,b)\n",
    "print('Train Accuracy: %f'%(np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6fdbe6b8-0555-4a7d-b1e5-ac7a2a02727b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 84.640000\n"
     ]
    }
   ],
   "source": [
    "#NORMALIZED ACCURACY\n",
    "p = predict(X_train_normal, w,b)\n",
    "print('Train Accuracy: %f'%(np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "68f99b89-27f8-4001-b2bc-37d973065d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 87.500000\n"
     ]
    }
   ],
   "source": [
    "#Z score accuracy\n",
    "p = predict(X_train_Z, w,b)\n",
    "print('Train Accuracy: %f'%(np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1eb747c2-59e5-4567-9694-00d0f81759fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 17.060000\n"
     ]
    }
   ],
   "source": [
    "#No scaler\n",
    "p = predict(X_train, w,b)\n",
    "print('Train Accuracy: %f'%(np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b4b104-cb03-4e9b-b662-6af0f7f918bf",
   "metadata": {},
   "source": [
    "# Regularized Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ad746268-7a2c-4d8b-9be6-163ca11104f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_reg(X, y, w, b, lambda_ = 1):\n",
    "    \"\"\"\n",
    "    Computes the cost over all examples\n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
    "      y : (ndarray Shape (m,))  target value\n",
    "      w : (ndarray Shape (n,))  values of parameters of the model\n",
    "      b : (scalar)              value of bias parameter of the model\n",
    "      lambda_ : (scalar, float) Controls amount of regularization\n",
    "    Returns:\n",
    "      total_cost : (scalar)     cost \n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    z = np.dot(X, w) + b\n",
    "    h = sigmoid(z)\n",
    "    \n",
    "    cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    regularization = (lambda_ / (2*m)) * np.sum(w**2)\n",
    "    \n",
    "    return cost + regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "aa47db92-4ab4-4c4d-806b-2a33937d6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient for regularized\n",
    "def compute_gradient_reg(X, y, w, b, lambda_):\n",
    "    \"\"\"\n",
    "    Computes the gradient for logistic regression with regularization\n",
    " \n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
    "      y : (ndarray Shape (m,))  target value \n",
    "      w : (ndarray Shape (n,))  values of parameters of the model      \n",
    "      b : (scalar)              value of bias parameter of the model\n",
    "      lambda_ : (scalar,float)  regularization constant\n",
    "    Returns\n",
    "      dj_db : (scalar)             The gradient of the cost w.r.t. the parameter b. \n",
    "      dj_dw : (ndarray Shape (n,)) The gradient of the cost w.r.t. the parameters w. \n",
    "\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    z = np.dot(X, w) + b\n",
    "    h = sigmoid(z)\n",
    "    \n",
    "    dj_dw = (1/m) * np.dot(X.T, (h - y)) + (lambda_ / m) * w\n",
    "    dj_db = (1/m) * np.sum(h - y)\n",
    "    \n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "52542333-9ad8-482f-9284-e71f9751864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_reg(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters, lambda_):\n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X :    (ndarray Shape (m, n) data, m examples by n features\n",
    "      y :    (ndarray Shape (m,))  target value \n",
    "      w_in : (ndarray Shape (n,))  Initial values of parameters of the model\n",
    "      b_in : (scalar)              Initial value of parameter of the model\n",
    "      cost_function :              function to compute cost\n",
    "      gradient_function :          function to compute gradient\n",
    "      alpha : (float)              Learning rate\n",
    "      num_iters : (int)            number of iterations to run gradient descent\n",
    "      lambda_ : (scalar, float)    regularization constant\n",
    "      \n",
    "    Returns:\n",
    "      w : (ndarray Shape (n,)) Updated values of parameters of the model after\n",
    "          running gradient descent\n",
    "      b : (scalar)                Updated value of parameter of the model after\n",
    "          running gradient descent\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    w = w_in\n",
    "    b = b_in\n",
    "    J_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        dj_dw, dj_db = gradient_function(X, y, w, b, lambda_)\n",
    "        \n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        \n",
    "        cost = cost_function(X, y, w, b, lambda_)\n",
    "        J_history.append(cost)\n",
    "        \n",
    "        if i % 1000 == 0 or i == num_iters - 1:\n",
    "            print(f\"Iteration {i:5d}: Cost {cost:.6f}\")\n",
    "    \n",
    "    return w, b, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2fdc2a16-8a9c-4d23-bea5-fb7156983b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration     0: Cost 0.691743\n",
      "Iteration  1000: Cost 0.343076\n",
      "Iteration  2000: Cost 0.310951\n",
      "Iteration  3000: Cost 0.302496\n",
      "Iteration  4000: Cost 0.299318\n",
      "Iteration  5000: Cost 0.297896\n",
      "Iteration  6000: Cost 0.297189\n",
      "Iteration  7000: Cost 0.296811\n",
      "Iteration  8000: Cost 0.296596\n",
      "Iteration  9000: Cost 0.296466\n",
      "Iteration 10000: Cost 0.296385\n",
      "Iteration 11000: Cost 0.296332\n",
      "Iteration 12000: Cost 0.296296\n",
      "Iteration 13000: Cost 0.296270\n",
      "Iteration 14000: Cost 0.296252\n",
      "Iteration 15000: Cost 0.296238\n",
      "Iteration 16000: Cost 0.296228\n",
      "Iteration 17000: Cost 0.296220\n",
      "Iteration 18000: Cost 0.296214\n",
      "Iteration 19000: Cost 0.296209\n",
      "Iteration 20000: Cost 0.296205\n",
      "Iteration 21000: Cost 0.296203\n",
      "Iteration 22000: Cost 0.296200\n",
      "Iteration 23000: Cost 0.296198\n",
      "Iteration 24000: Cost 0.296197\n",
      "Iteration 25000: Cost 0.296196\n",
      "Iteration 26000: Cost 0.296195\n",
      "Iteration 27000: Cost 0.296194\n",
      "Iteration 28000: Cost 0.296194\n",
      "Iteration 29000: Cost 0.296193\n",
      "Iteration 30000: Cost 0.296193\n",
      "Iteration 31000: Cost 0.296192\n",
      "Iteration 32000: Cost 0.296192\n",
      "Iteration 33000: Cost 0.296192\n",
      "Iteration 34000: Cost 0.296192\n",
      "Iteration 35000: Cost 0.296192\n",
      "Iteration 36000: Cost 0.296192\n",
      "Iteration 37000: Cost 0.296191\n",
      "Iteration 38000: Cost 0.296191\n",
      "Iteration 39000: Cost 0.296191\n",
      "Iteration 39999: Cost 0.296191\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros(X_train_Z.shape[1])\n",
    "initial_b = 0.0\n",
    "iterations = 40000\n",
    "alpha = 0.008  # Slightly higher than original\n",
    "lambda_ = 0.1  # Decreased from 0.5\n",
    "w2, b2, J_history2 = gradient_descent_reg(X_train_Z, y_train, initial_w, initial_b, compute_cost_reg, compute_gradient_reg, alpha, iterations, lambda_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d5afc338-c69f-4373-8fbe-b4e7a883611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 87.500000\n"
     ]
    }
   ],
   "source": [
    "p = predict(X_train_Z, w, b)\n",
    "\n",
    "print('Train Accuracy: %f'%(np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccce393-11d0-4fcf-9346-a781cab94d06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
